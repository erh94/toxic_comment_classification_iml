{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "[[6, 2, 7], [3, 1], [8, 4], [9, 1], [10], [11], [5, 4], [12, 3], [5, 1], [13, 14, 15, 2, 16]]\n",
      "[[ 6  2  7  0]\n",
      " [ 3  1  0  0]\n",
      " [ 8  4  0  0]\n",
      " [ 9  1  0  0]\n",
      " [10  0  0  0]\n",
      " [11  0  0  0]\n",
      " [ 5  4  0  0]\n",
      " [12  3  0  0]\n",
      " [ 5  1  0  0]\n",
      " [14 15  2 16]]\n"
     ]
    }
   ],
   "source": [
    "docs = ['Well done himanshu!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could digvijay have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(vocab_size)\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('./embeddings/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "# print('vector for the %s:' %embeddings_index['the'])\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13941   -0.93446   -1.1699    -0.45358   -0.80969   -0.4697\n",
      " -0.4306    -0.10754    0.18795   -0.54211   -0.15869    0.51521\n",
      " -0.60895   -0.45044    0.28322    0.13901   -0.18377   -0.6235\n",
      "  0.081157   0.26575    0.46618    0.18926   -0.09531    0.37706\n",
      "  0.15525   -0.28393    0.043943   0.53832   -0.31614    0.30335\n",
      " -0.12475   -0.53195    0.26536    0.29936   -0.38363   -1.2319\n",
      "  0.36661    0.0081704 -0.18437   -0.2652     0.64792    0.52518\n",
      " -0.65007    0.01841   -0.45358    0.089317  -0.28032    0.35339\n",
      " -0.87161   -0.089397   0.27014   -0.37721    0.20029   -0.4886\n",
      "  0.48372    0.36473   -0.95744    0.19025   -0.9574     0.22165\n",
      "  0.25551    0.21751    0.51237    0.43257   -0.12989    0.13111\n",
      "  0.015008   0.34065    0.072318   0.23782   -0.38093    0.38866\n",
      " -0.15616   -0.72631    0.1174    -0.015549  -0.079929  -0.31292\n",
      " -0.47915   -0.86838    0.75062   -0.53634    0.11207   -0.50418\n",
      "  0.49805    0.23473   -0.38806   -0.4929    -0.14628    0.56443\n",
      "  0.49264   -0.015154  -0.014764  -0.98412    1.1631     0.73653\n",
      "  0.26903    0.57752   -0.81464    0.092908 ]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_index['himanshu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.0950e-01 -1.1155e+00  2.8152e-01  5.0814e-01 -3.1374e-01 -9.3150e-01\n",
      " -7.0727e-01  4.1357e-01 -3.3395e-01  1.0936e-01 -2.8128e-01  4.8444e-01\n",
      " -6.2852e-01  4.8379e-01 -5.1407e-01  1.7102e-01 -2.9693e-01  5.3141e-02\n",
      " -5.2709e-01 -3.9502e-01 -4.1282e-01 -1.6546e-01 -2.2641e-01 -1.0160e-01\n",
      " -5.4754e-01  2.7468e-01  7.3284e-02  2.7656e-01  5.5873e-01 -2.4545e-01\n",
      " -2.1480e-02  1.0476e-01 -1.8919e-01 -5.7671e-01 -2.3631e-02 -1.9370e-01\n",
      " -6.3918e-01  1.5371e-01  2.5235e-02  3.8918e-02  4.2876e-01  3.0519e-01\n",
      "  6.1021e-01  3.8187e-01 -1.7824e-01 -3.9837e-01  8.2345e-01  4.7700e-01\n",
      " -6.1068e-01  4.3747e-01 -4.3080e-01 -4.4698e-01 -1.1411e-01 -4.5047e-01\n",
      "  3.7518e-01  5.6153e-01 -1.4936e-01  1.9613e-01 -5.1872e-02  2.7713e-01\n",
      "  8.2881e-02 -6.2014e-01  8.2520e-01  4.7665e-01  2.1820e-01  3.3784e-01\n",
      "  6.9790e-01  4.8402e-02  9.5558e-01  2.1312e-02  1.1956e-02 -1.1321e-01\n",
      "  2.1801e-01  2.9487e-01 -3.0471e-01  7.9353e-01 -6.0281e-01  6.7348e-01\n",
      "  3.1860e-01 -2.3025e-01 -4.1566e-01 -3.7357e-01  6.7079e-02 -4.1768e-01\n",
      "  3.3210e-01 -2.6120e-01 -5.2497e-01  8.3148e-02 -3.0740e-01  6.1535e-02\n",
      "  4.6789e-01  1.7689e-01  1.6444e-01  9.5000e-04  1.8513e-01 -6.7355e-02\n",
      "  6.7485e-01 -3.9036e-01 -3.2579e-01 -9.3722e-01]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_index['digvijay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 100)            1700      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 2,101\n",
      "Trainable params: 401\n",
      "Non-trainable params: 1,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=4, trainable=False)\n",
    "model.add(e)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=array([\n",
    "[ 6,  2,  7,  0],\n",
    "[ 3,  1,  0,  0],\n",
    "[ 8,  4,  0,  0],\n",
    "[ 9,  1,  0,  0],\n",
    "[10,  0,  0,  0],\n",
    "[11,  0,  0,  0],\n",
    "[ 5,  4,  0,  0],\n",
    "[12,  3,  0,  0],\n",
    "[ 5,  1,  0,  0],\n",
    "[14, 15,  2, 16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8853457 ],\n",
       "       [0.70829594],\n",
       "       [0.73753446],\n",
       "       [0.81827193],\n",
       "       [0.71885693],\n",
       "       [0.31836343],\n",
       "       [0.2573215 ],\n",
       "       [0.2365119 ],\n",
       "       [0.31570247],\n",
       "       [0.05443963]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
